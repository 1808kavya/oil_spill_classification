{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Network\n",
    "\n",
    "Le **Artificial Neural Network**, (_NN_) sono modelli matematici largamente utilizzati nel campo dell'**Intelligenza Artificiale** (_AI_) che permettono, a sistemi automatici, di compiere task complessi e articolati che dei semplici algoritmi (es. algoritmi sequenziali) non sarebbero in grado di portare a termine in modo rapido ed efficace.\n",
    "\n",
    "Le basi di questo metodo risalgono alla metà del XX secolo quando per la prima volta furono proposti algoritmi per l'apprendimento automatico. L'obiettivo era quello di creare _strutture_ in grado di modellare un determinato fenomeno e riproporne il comportamento in determinate condizioni.\n",
    "\n",
    "Il componente base di questa nuova struttura è il _**neurone**_. Con questo termine identifichiamo un nodo in grado di simulare il comportamento di un neurone biologico e di interconnettersi con altri neuroni al fine di creare una rete. Ogni nodo elabora i segnali ricevuti e trasmette il risultato a nodi successivi.\n",
    "\n",
    "Un tipico esempio di struttura base di queste reti è il **percettrone**:\n",
    "![Percettrone](./img/percetrone.png)\n",
    "\n",
    "Ogni singolo ingresso di questi nodi riceve informazioni che vengono elaborate. L'elaborazione, che in base agli ingressi può diventare complessa, si può pensare come singoli ingressi che vengono moltiplicati per un opportuno valore detto peso. Il risultato ottenuto delle moltiplicazioni viene sommato e se la somma supera una certa soglia il neurone attiva la sua uscita. Il peso serve a quantificare l'importanza di una interconnessione, infatti un ingresso molto importante avrà un peso elevato, mentre un ingresso poco utile all'elaborazione avrà un peso inferiore.\n",
    "\n",
    "Ponendo in cascata e combinando tra loro più più neuroni generiamo quella che definiamo _NN_.\n",
    "![ANN](./img/ann.png)\n",
    "\n",
    "L'utilizzo delle NN è tornato in uso dopo la reinvenzione dell’algoritmo di apprendimento chiamato back-propagation. Questo algoritmo infatti permette di modificare i pesi delle interconnessioni in modo tale che si minimizzi una certa funzione errore E.\n",
    "\n",
    "Con l'avvento di nuove metodologie come il **machine learning** e l'aumento della performance delle NN il campo dell'intelligenza artificiale è diventato tra i più importanti ambiti di ricerca nella computer scienze. Grazie a questo, i risultati e i campi applicativi acquisiscono, di giorno in giorno, maggiore interesse. Siamo così passati ad analizzare, attraverso le _NN_, problemi sempre più complessi: è l'avvento del **deep learning**.\n",
    "\n",
    "Nelle reti neurali classiche moderne è possibile riscontrare la presenza di qualche strato nascosto. Questi strati, denominati _hidden layers_, possono essere interpretati come il _cuore_ della rete stessa poiché sono quelli che si occupano di interpretare le features sottomesse alla rete.\n",
    "\n",
    "![NN](./img/simple_neural_network_header.jpg)\n",
    "\n",
    "Con il deep learning, invece, siamo rapportati a problemi più complessi: _dal riconoscimento ed interpretazione del linguaggio naturale fino alla visione artificiale_. Nei modelli deep ogni singolo stato nascosto potrebbe essere paragonato ad una piccola rete neurale classica: ponendone in cascata una all'altra possiamo ottenere modelli complessi per la gestione di task anche molto avanzati come ad esempio gli algoritmi di visione per l'_automotive_\n",
    "\n",
    "![deep](./img/deep.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso di studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codice utlizzato per la Neural Network applicato al  nostro caso di studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il nostro dataset è composto da 3815 elementi ognuno dei quali è descritto attraverso 31 features. In questo primo approccio viene mostrato come addestrare una rete neurale classica sia attraverso la classica strarificazione per determinare dataset di treaning e test, sia con la cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout\n",
    "# keras libraries\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "# sklearn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# convolutional network parmas\n",
    "path_dataset = './dataset/dataset_total.txt'  # datasetpath\n",
    "path_best = './best_model/'  # kfolds model path\n",
    "path_thebest = './thebetter_model/'  # bset models path\n",
    "\n",
    "# neural network params\n",
    "batch_size = 32  # training cases batch\n",
    "num_epochs = 500  # max number of epochs\n",
    "num_classes = 3  # number of class in dataset\n",
    "seed = 42  # base random seed\n",
    "n_splits = 10  # number of kfold\n",
    "n_input_layer = 31 # number of inputs layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo la funzione utile per il caricamento del dataset e il suo _splitting_ in porzione di test e di training. La strategia adottata è quella della stratificazione: ovvero creare du insiemi nei quali la \"_concentrazione_\" dei vari esempi sia equipollente. Ad esempio, se nel dataset di training ci sono il 30% dei campioni di tipo 1 il 40% di tipo 2 e 30% dei campioni di tipo 3, le stesse percentuali saranno adottate per il dataset di test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_nn():\n",
    "    \"\"\"\n",
    "    generate dataset based on data in dataset folder\n",
    "    :return: train and test dataset based on stratification strategy\n",
    "    \"\"\"\n",
    "    dataset = np.loadtxt(path_dataset, delimiter='\\t')\n",
    "\n",
    "    y = np.array(np.ceil(dataset[:, -1])).astype(np.str)\n",
    "    X = np.array(dataset[:, :-1]).astype(np.float32)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=seed, stratify=y)\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "\n",
    "    X_train = scaler.transform(x_train)\n",
    "    X_test = scaler.transform(x_test)\n",
    "\n",
    "    y_train = np.subtract(y_train.reshape((len(y_train), 1)).astype(np.float32), np.asarray(2.0))\n",
    "    y_test = np.subtract(y_test.reshape((len(y_test), 1)).astype(np.float32), np.asarray(2.0))\n",
    "\n",
    "    Y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "    Y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo la funzione che instanzierà il modello della nostra rete neurale. La struttura segue i seguenti parametri:\n",
    " - primo livello di ingresso con 31 neuroni. Idealmente sarebbero 1 per ciascuna delle features\n",
    " - 4 livelli nascoti con lo stesso numero di neuroni e funzione di attivazione _elu_[1](#cite-DBLP:journals-corr-ClevertUH15).\n",
    " - 4 livelli di _Dropout_, ciascuno dopo ogni livello nascoto\n",
    " - ultimo livello con 3 neuroni e _softmax_ come funzione di attivazione\n",
    " - la funzione di perdita da minimizzare è la _binary_crossentropy_ attraverso l'ottimizzazione _adadelta_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    \"\"\"\n",
    "    Definition of neural network base model\n",
    "    :return: model\n",
    "    \"\"\"\n",
    "    base_model = Sequential()\n",
    "    base_model.add(Dense(n_input_layer, activation='elu',  input_shape=(X_train.shape[1],)))\n",
    "    #hidden\n",
    "    base_model.add(Dense(31, activation='elu'))\n",
    "    base_model.add(Dropout(0.1))\n",
    "    base_model.add(Dense(31, activation='elu'))\n",
    "    base_model.add(Dropout(0.1))\n",
    "    base_model.add(Dense(31, activation='elu'))\n",
    "    base_model.add(Dropout(0.1))\n",
    "    base_model.add(Dense(31, activation='elu'))\n",
    "    base_model.add(Dropout(0.3))\n",
    "    base_model.add(Dense(3, activation='softmax'))\n",
    "    base_model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo una funzione per la valutazione del modello migliore in uscita dal processo di addestramento in cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "format": "row"
   },
   "outputs": [],
   "source": [
    "def evaluete_nn(X_test, Y_test, best_model=None, model=None):\n",
    "    \"\"\"\n",
    "    Evaluate best model after kfold training\n",
    "    :param X_test: example images to test best model after kfold\n",
    "    :param Y_test: labels matching truth to example\n",
    "    :param best_model: index which identify best model after kfold\n",
    "    :return: evaluation of best model trough dataset test and save it with loss and accuracy metrics\n",
    "    \"\"\"\n",
    "\n",
    "    # load best model and evaluate it with accuracy and loss\n",
    "    if(model==None):\n",
    "        print('Load best model and test it ')\n",
    "        model = load_model(path_best+'checkpoint-%d.h5' %(best_model))\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)  # evaluate model\n",
    "    y_predict = np.asarray(model.predict(X_test, verbose=0))\n",
    "    Y_predict = np.argmax(y_predict, axis=1)\n",
    "    y_test = np.argmax(Y_test, axis=1)\n",
    "    confmatrix = confusion_matrix(y_test, Y_predict)\n",
    "    print(\"\\nConfusion Matrix :\")\n",
    "    print(confmatrix)\n",
    "    class_names = [\"0\", \"1\", '2']\n",
    "    print(\"\\nMetrics => \", model.metrics_names, score)\n",
    "    print('\\nClassification Report : ')\n",
    "    print(classification_report(y_test, Y_predict, target_names=class_names))\n",
    "    # save model tested with loss and accuracy\n",
    "    model.save(path_thebest+'model-'+'{:.4f}'.format(score[0])+'-'+'{:.4f}'.format(score[1])+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING FITTING NEURAL NETWORK\n",
      "loading data .......\n",
      "\n",
      "train examples:\n",
      "2670\n",
      "test examples:\n",
      "1145\n"
     ]
    }
   ],
   "source": [
    "print('STARTING FITTING NEURAL NETWORK')\n",
    "if os.path.exists(path_best):\n",
    "    shutil.rmtree(path_best)\n",
    "os.mkdir(path_best)\n",
    "if not os.path.exists(path_thebest):\n",
    "    os.mkdir(path_thebest)\n",
    "\n",
    "print('loading data .......\\n')\n",
    "X_train, X_test, Y_train, Y_test = load_data_nn()\n",
    "\n",
    "print('train examples:')\n",
    "print(len(X_train))\n",
    "print('test examples:')\n",
    "print(len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addestriamo inizialmente la rete neurale senza sfruttare la cross validation. Imponiamo un numero massimo di iterazioni pari a 500. Poiché, a casusa dello sbilanciamento del dataset, incorreremo sicuramente in overfitting per gli elementi di appartenenti alla classe _low_risk_, imponiamo anche un **EarlyStopping**, ovvero un listner che monitora l'andamento della funzione di perdita che stiamo minimizzando e, se questa non dovesse avare variazioni pari ad un delta di _0.001_ per più di 10 iterazioni, blocchi l'addestramento della rete se necessario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2670/2670 [==============================] - 0s 68us/step - loss: 0.3355 - acc: 0.8767\n",
      "Epoch 2/500\n",
      "2670/2670 [==============================] - 0s 57us/step - loss: 0.1546 - acc: 0.9548\n",
      "Epoch 3/500\n",
      "2670/2670 [==============================] - 0s 57us/step - loss: 0.1336 - acc: 0.9576\n",
      "Epoch 4/500\n",
      "2670/2670 [==============================] - 0s 61us/step - loss: 0.1225 - acc: 0.9598\n",
      "Epoch 5/500\n",
      "2670/2670 [==============================] - 0s 61us/step - loss: 0.1224 - acc: 0.9599\n",
      "Epoch 6/500\n",
      "2670/2670 [==============================] - 0s 58us/step - loss: 0.1140 - acc: 0.9604\n",
      "Epoch 7/500\n",
      "2670/2670 [==============================] - 0s 58us/step - loss: 0.1119 - acc: 0.9576\n",
      "Epoch 8/500\n",
      "2670/2670 [==============================] - 0s 58us/step - loss: 0.1076 - acc: 0.9599\n",
      "Epoch 9/500\n",
      "2670/2670 [==============================] - 0s 57us/step - loss: 0.1081 - acc: 0.9594\n",
      "Epoch 10/500\n",
      "2670/2670 [==============================] - 0s 60us/step - loss: 0.1063 - acc: 0.9605\n",
      "Epoch 11/500\n",
      "2670/2670 [==============================] - 0s 58us/step - loss: 0.1075 - acc: 0.9610\n",
      "Epoch 12/500\n",
      "2670/2670 [==============================] - 0s 57us/step - loss: 0.1065 - acc: 0.9599\n",
      "Epoch 13/500\n",
      "2670/2670 [==============================] - 0s 55us/step - loss: 0.1044 - acc: 0.9602\n",
      "Epoch 14/500\n",
      "2670/2670 [==============================] - 0s 59us/step - loss: 0.1034 - acc: 0.9612\n",
      "Epoch 15/500\n",
      "2670/2670 [==============================] - 0s 58us/step - loss: 0.1005 - acc: 0.9629\n",
      "Epoch 16/500\n",
      "2670/2670 [==============================] - 0s 72us/step - loss: 0.0989 - acc: 0.9617\n",
      "Epoch 17/500\n",
      "2670/2670 [==============================] - 0s 101us/step - loss: 0.0968 - acc: 0.9604\n",
      "Epoch 18/500\n",
      "2670/2670 [==============================] - 0s 96us/step - loss: 0.0986 - acc: 0.9619\n",
      "Epoch 19/500\n",
      "2670/2670 [==============================] - 0s 59us/step - loss: 0.0978 - acc: 0.9649\n",
      "Epoch 20/500\n",
      "2670/2670 [==============================] - 0s 60us/step - loss: 0.0977 - acc: 0.9640\n",
      "Epoch 21/500\n",
      "2670/2670 [==============================] - 0s 57us/step - loss: 0.1000 - acc: 0.9629\n",
      "Epoch 22/500\n",
      "2670/2670 [==============================] - 0s 60us/step - loss: 0.1010 - acc: 0.9615\n",
      "Epoch 23/500\n",
      "2670/2670 [==============================] - 0s 66us/step - loss: 0.0943 - acc: 0.9623\n",
      "Epoch 24/500\n",
      "2670/2670 [==============================] - 0s 56us/step - loss: 0.0979 - acc: 0.9614\n",
      "Epoch 25/500\n",
      "2670/2670 [==============================] - 0s 62us/step - loss: 0.0919 - acc: 0.9643\n",
      "Epoch 26/500\n",
      "2670/2670 [==============================] - 0s 59us/step - loss: 0.0946 - acc: 0.9632\n",
      "Epoch 27/500\n",
      "2670/2670 [==============================] - 0s 57us/step - loss: 0.0935 - acc: 0.9653\n",
      "Epoch 28/500\n",
      "2670/2670 [==============================] - 0s 58us/step - loss: 0.0890 - acc: 0.9663\n",
      "Epoch 29/500\n",
      "2670/2670 [==============================] - 0s 57us/step - loss: 0.0937 - acc: 0.9634\n",
      "Epoch 30/500\n",
      "2670/2670 [==============================] - 0s 63us/step - loss: 0.0944 - acc: 0.9644\n",
      "Epoch 31/500\n",
      "2670/2670 [==============================] - 0s 56us/step - loss: 0.0914 - acc: 0.9657\n",
      "Epoch 32/500\n",
      "2670/2670 [==============================] - 0s 61us/step - loss: 0.0927 - acc: 0.9618\n",
      "Epoch 33/500\n",
      "2670/2670 [==============================] - 0s 63us/step - loss: 0.0909 - acc: 0.9652\n",
      "Epoch 34/500\n",
      "2670/2670 [==============================] - 0s 60us/step - loss: 0.0906 - acc: 0.9632\n",
      "Epoch 35/500\n",
      "2670/2670 [==============================] - 0s 66us/step - loss: 0.0889 - acc: 0.9638\n",
      "Epoch 36/500\n",
      "2670/2670 [==============================] - 0s 58us/step - loss: 0.0886 - acc: 0.9644\n",
      "Epoch 37/500\n",
      "2670/2670 [==============================] - 0s 61us/step - loss: 0.0889 - acc: 0.9668\n",
      "Epoch 38/500\n",
      "2670/2670 [==============================] - 0s 58us/step - loss: 0.0890 - acc: 0.9640\n",
      "Epoch 00038: early stopping\n",
      "acc: 96.80%\n"
     ]
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "model.fit(X_train, Y_train, epochs=num_epochs, batch_size=batch_size, verbose=1,\n",
    "          callbacks=[TensorBoard(log_dir='./nn/tensorboard/'),\n",
    "                     EarlyStopping(monitor='loss', min_delta=0.001, patience=10, verbose=2, mode='min')])\n",
    "scores = model.evaluate(X_train, Y_train, verbose=2)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valutiamo ora le performance del modello addestrato sul dataset di test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics =>  ['loss', 'acc'] [0.10511936141934457, 0.96593887129204759]\n",
      "\n",
      "Confusion Matrix :\n",
      "[[1073    0    5]\n",
      " [  18    5    3]\n",
      " [  31    0   10]]\n",
      "\n",
      "Metrics =>  ['loss', 'acc'] [0.10511936141934457, 0.96593887129204759]\n",
      "\n",
      "Classification Report : \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      1078\n",
      "          1       1.00      0.19      0.32        26\n",
      "          2       0.56      0.24      0.34        41\n",
      "\n",
      "avg / total       0.94      0.95      0.94      1145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluete_nn(X_test, Y_test, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passando all'utilizzo della cross validation, utilizziamo per la rete la stessa accortezza utilizzata in precedenza con **EarlyStopping**, in più imponiamo che per ogni *k\\_fold* venga salvato il miglior modello in un path specifico. Assieme al modello salviamo anche, per ciasun *best\\_model*, anche i rispettivi valori di _accurancy_ in un vettore (_**cvscores**_). In questo modo, alla fine dell'iterazione dei vari k_fold, possiamo selezionare il *better\\_model* da valutare con il dataset di test.\n",
    "Il risultato finale fornisce anche un valore di media per l'accuratezza valutata su tutti i modelli risultati migliori per ciascun k_fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00043: early stopping\n",
      "acc: 96.50%\n",
      "Epoch 00060: early stopping\n",
      "acc: 96.88%\n",
      "Epoch 00053: early stopping\n",
      "acc: 96.00%\n",
      "Epoch 00049: early stopping\n",
      "acc: 96.25%\n",
      "Epoch 00047: early stopping\n",
      "acc: 96.88%\n",
      "Epoch 00032: early stopping\n",
      "acc: 96.63%\n",
      "Epoch 00048: early stopping\n",
      "acc: 94.26%\n",
      "Epoch 00042: early stopping\n",
      "acc: 96.75%\n",
      "Epoch 00053: early stopping\n",
      "acc: 96.25%\n",
      "Epoch 00058: early stopping\n",
      "acc: 97.75%\n",
      "96.42% (+/- 0.85%)\n"
     ]
    }
   ],
   "source": [
    "# generation kfolds to cross validation process\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "i = 0\n",
    "\n",
    "# start cross validation\n",
    "for train, test in kfold.split(X_train, Y_train):\n",
    "    model = baseline_model()\n",
    "    model.fit(X_train[train], Y_train[train], epochs=num_epochs, batch_size=batch_size, verbose=0,\n",
    "              callbacks=[TensorBoard(log_dir='./nn/tensorboard/'),\n",
    "                         ModelCheckpoint(path_best+'checkpoint-%d.h5' %(i), monitor='acc', verbose=0,\n",
    "                                         save_best_only=True, mode='max'),\n",
    "                         EarlyStopping(monitor='loss', min_delta=0.001, patience=10, verbose=2, mode='min')])\n",
    "    scores = model.evaluate(X_train[test], Y_train[test], verbose=2)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    i += 1\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto è opportuno valutare il miglior moello tra quelli risultati ottimali per ciascun k_fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "format": "row"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load best model and test it \n",
      "\n",
      "Confusion Matrix :\n",
      "[[1078    0    0]\n",
      " [  18    7    1]\n",
      " [  35    1    5]]\n",
      "\n",
      "Metrics =>  ['loss', 'acc'] [0.11256823928205206, 0.96797671541896968]\n",
      "\n",
      "Classification Report : \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      1078\n",
      "          1       0.88      0.27      0.41        26\n",
      "          2       0.83      0.12      0.21        41\n",
      "\n",
      "avg / total       0.95      0.95      0.94      1145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate best model based on higher accuracy\n",
    "vect_max = np.argmax(cvscores)\n",
    "evaluete_nn(X_test, Y_test, best_model=vect_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Considerazioni\n",
    "\n",
    "Analizzando le metriche base di entrambi i casi di addestramento, possiamo notare che gli andamenti sono pressoché uguali, con una precisione del 96%. Il dato che ci consente di percepire che l'addestramento effettuato con la cross validation sia in qualche modo migliore, ci viene fornito dal report dalla cufusion matrix: nel primo caso si nota chiaramente un che il modello soffre di overfitting per la classe 0 e non ha ottimi riscontri per gli elementi di classe 2 (in questo caso ha una precisione al di sotto del 60%). Mentre per la classe 1, nonostante una precisione molto alta, la recall è molto bassa addirirttura sotto il 20%.\n",
    "\n",
    "Nel caso di addestramento con la tecnica della cross validazione, benché non possiamo dirci del tutto fuori dal fenomeno di overfitting, possiamo notare una migliore precisione per gli elementi di classe 1 e classe 2. In questo caso siamo oltre il valore di 80% percento per la classe 2, e di poco sotto il 90% per la classe 1. Anche in questo caso la recall per queste 2 classi è molto bassa, indice chiaro di una forte tendenza verso l'overfitting.\n",
    "\n",
    "L'utilizzo della cross validation, per evitare o attenuare il fenomeno di overfitting sul modello, è stato dettato dal voler rendere il modello il più vicino possibile al _mondo reale_. Infatti, avremmo potuto utilizzare tecniche di _**data augumentation**_ per creare esempi _artificiali_ della classe 1 e della classe 2, avremmo però reso il modello fittizio e molto lontano dal caso reale nel quale dovrebbe agire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codice utlizzato per la Deep Neural Network applicato al  nostro caso di studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
