{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Network\n",
    "\n",
    "Le **Artificial Neural Network**, (_NN_) sono modelli matematici largamente utilizzati nel campo dell'**Intelligenza Artificiale** (_AI_) che permettono, a sistemi automatici, di compiere task complessi e articolati che dei semplici algoritmi (es. algoritmi sequenziali) non sarebbero in grado di portare a termine in modo rapido ed efficace.\n",
    "\n",
    "Le basi di questo metodo risalgono alla metà del XX secolo quando per la prima volta furono proposti algoritmi per l'apprendimento automatico. L'obiettivo era quello di creare _strutture_ in grado di modellare un determinato fenomeno e riproporne il comportamento in determinate condizioni.\n",
    "\n",
    "Il componente base di questa nuova struttura è il _**neurone**_. Con questo termine identifichiamo un nodo in grado di simulare il comportamento di un neurone biologico e di interconnettersi con altri neuroni al fine di creare una rete. Ogni nodo elabora i segnali ricevuti e trasmette il risultato a nodi successivi.\n",
    "\n",
    "Un tipico esempio di struttura base di queste reti è il **percettrone**:\n",
    "![Percettrone](./img/percetrone.png)\n",
    "\n",
    "Ogni singolo ingresso di questi nodi riceve informazioni che vengono elaborate. L'elaborazione, che in base agli ingressi può diventare complessa, si può pensare come singoli ingressi che vengono moltiplicati per un opportuno valore detto peso. Il risultato ottenuto delle moltiplicazioni viene sommato e se la somma supera una certa soglia il neurone attiva la sua uscita. Il peso serve a quantificare l'importanza di una interconnessione, infatti un ingresso molto importante avrà un peso elevato, mentre un ingresso poco utile all'elaborazione avrà un peso inferiore.\n",
    "\n",
    "Ponendo in cascata e combinando tra loro più più neuroni generiamo quella che definiamo _NN_.\n",
    "![ANN](./img/ann.png)\n",
    "\n",
    "L'utilizzo delle NN è tornato in uso dopo la reinvenzione dell’algoritmo di apprendimento chiamato back-propagation. Questo algoritmo infatti permette di modificare i pesi delle interconnessioni in modo tale che si minimizzi una certa funzione errore E.\n",
    "\n",
    "Con l'avvento di nuove metodologie come il **machine learning** e l'aumento della performance delle NN il campo dell'intelligenza artificiale è diventato tra i più importanti ambiti di ricerca nella computer scienze. Grazie a questo, i risultati e i campi applicativi acquisiscono, di giorno in giorno, maggiore interesse. Siamo così passati ad analizzare, attraverso le _NN_, problemi sempre più complessi: è l'avvento del **deep learning**.\n",
    "\n",
    "Nelle reti neurali classiche moderne è possibile riscontrare la presenza di qualche strato nascosto. Questi strati, denominati _hidden layers_, possono essere interpretati come il _cuore_ della rete stessa poiché sono quelli che si occupano di interpretare le features sottomesse alla rete.\n",
    "\n",
    "![NN](./img/simple_neural_network_header.jpg)\n",
    "\n",
    "Con il deep learning, invece, siamo rapportati a problemi più complessi: _dal riconoscimento ed interpretazione del linguaggio naturale fino alla visione artificiale_. Nei modelli deep ogni singolo stato nascosto potrebbe essere paragonato ad una piccola rete neurale classica: ponendone in cascata una all'altra possiamo ottenere modelli complessi per la gestione di task anche molto avanzati come ad esempio gli algoritmi di visione per l'_automotive_\n",
    "\n",
    "![deep](./img/deep.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Codice utlizzato per la Neural Network del caso di studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout\n",
    "# keras libraries\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# project libraries\n",
    "from src.nn.keras_nn import load_data_nn\n",
    "\n",
    "# convolutional network parmas\n",
    "path_dataset = './dataset/dataset_total.txt'  # datasetpath\n",
    "path_best = './best_model/'  # kfolds model path\n",
    "path_thebest = './thebetter_model/'  # bset models path\n",
    "\n",
    "# neural network params\n",
    "batch_size = 32  # training cases batch\n",
    "num_epochs = 500  # max number of epochs\n",
    "num_classes = 3  # number of class in dataset\n",
    "seed = 42  # base random seed\n",
    "n_splits = 10  # number of kfold\n",
    "n_input_layer = 31 # number of inputs layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_nn():\n",
    "    \"\"\"\n",
    "    generate dataset based on data in dataset folder\n",
    "    :return: train and test dataset based on stratification strategy\n",
    "    \"\"\"\n",
    "    dataset = np.loadtxt(path_dataset, delimiter='\\t')\n",
    "\n",
    "    y = np.array(np.ceil(dataset[:, -1])).astype(np.str)\n",
    "    X = np.array(dataset[:, :-1]).astype(np.float32)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=seed, stratify=y)\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "\n",
    "    X_train = scaler.transform(x_train)\n",
    "    X_test = scaler.transform(x_test)\n",
    "\n",
    "    y_train = np.subtract(y_train.reshape((len(y_train), 1)).astype(np.float32), np.asarray(2.0))\n",
    "    y_test = np.subtract(y_test.reshape((len(y_test), 1)).astype(np.float32), np.asarray(2.0))\n",
    "\n",
    "    Y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "    Y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    \"\"\"\n",
    "    Definition of neural network base model\n",
    "    :return: model\n",
    "    \"\"\"\n",
    "    base_model = Sequential()\n",
    "    base_model.add(Dense(n_input_layer, activation='elu',  input_shape=(X_train.shape[1],)))\n",
    "    #hidden\n",
    "    base_model.add(Dense(31, activation='elu'))\n",
    "    base_model.add(Dropout(0.1))\n",
    "    base_model.add(Dense(31, activation='elu'))\n",
    "    base_model.add(Dropout(0.1))\n",
    "    base_model.add(Dense(31, activation='elu'))\n",
    "    base_model.add(Dropout(0.1))\n",
    "    base_model.add(Dense(31, activation='elu'))\n",
    "    base_model.add(Dropout(0.3))\n",
    "    base_model.add(Dense(3, activation='softmax'))\n",
    "    base_model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluete_nn(X_test, Y_test, best_model):\n",
    "    \"\"\"\n",
    "    Evaluate best model after kfold training\n",
    "    :param X_test: example images to test best model after kfold\n",
    "    :param Y_test: labels matching truth to example\n",
    "    :param best_model: index which identify best model after kfold\n",
    "    :return: evaluation of best model trough dataset test and save it with loss and accuracy metrics\n",
    "    \"\"\"\n",
    "\n",
    "    # load best model and evaluate it with accuracy and loss\n",
    "    print('Load best model and test it ')\n",
    "    model = load_model(path_best+'checkpoint-%d.h5' %(best_model))\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)  # evaluate model\n",
    "    print('Metrics => ', model.metrics_names, score)\n",
    "    y_predict = np.asarray(model.predict(X_test, verbose=0))\n",
    "    Y_predict = np.argmax(y_predict, axis=1)\n",
    "    y_test = np.argmax(Y_test, axis=1)\n",
    "    confmatrix = confusion_matrix(y_test, Y_predict)\n",
    "    print(\"\\nConfusion Matrix :\")\n",
    "    print(confmatrix)\n",
    "    class_names = [\"0\", \"1\", '2']\n",
    "    print(\"\\nMetrics => \", model.metrics_names, score)\n",
    "    print('\\nClassification Report : ')\n",
    "    print(classification_report(y_test, Y_predict, target_names=class_names))\n",
    "    # save model tested with loss and accuracy\n",
    "    model.save(path_thebest+'model-'+'{:.4f}'.format(score[0])+'-'+'{:.4f}'.format(score[1])+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING FITTING NEURAL NETWORK\n",
      "loading data .......\n"
     ]
    }
   ],
   "source": [
    "print('STARTING FITTING NEURAL NETWORK')\n",
    "if os.path.exists(path_best):\n",
    "    shutil.rmtree(path_best)\n",
    "os.mkdir(path_best)\n",
    "if not os.path.exists(path_thebest):\n",
    "    os.mkdir(path_thebest)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = load_data_nn()\n",
    "\n",
    "print('loading data .......')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00052: early stopping\n",
      "acc: 96.13%\n",
      "Epoch 00041: early stopping\n",
      "acc: 97.50%\n",
      "Epoch 00056: early stopping\n",
      "acc: 95.76%\n",
      "Epoch 00037: early stopping\n",
      "acc: 96.88%\n",
      "Epoch 00037: early stopping\n",
      "acc: 96.50%\n",
      "Epoch 00054: early stopping\n",
      "acc: 96.25%\n",
      "Epoch 00031: early stopping\n",
      "acc: 94.51%\n",
      "Epoch 00046: early stopping\n",
      "acc: 96.88%\n",
      "Epoch 00041: early stopping\n",
      "acc: 96.38%\n",
      "Epoch 00056: early stopping\n",
      "acc: 97.25%\n",
      "96.40% (+/- 0.81%)\n",
      "Load best model and test it \n",
      "Metrics =>  ['loss', 'acc'] [0.095308599793494528, 0.96855895196506547]\n",
      "\n",
      "Confusion Matrix :\n",
      "[[1077    0    1]\n",
      " [  18    7    1]\n",
      " [  34    0    7]]\n",
      "\n",
      "Metrics =>  ['loss', 'acc'] [0.095308599793494528, 0.96855895196506547]\n",
      "\n",
      "Classification Report : \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      1078\n",
      "          1       1.00      0.27      0.42        26\n",
      "          2       0.78      0.17      0.28        41\n",
      "\n",
      "avg / total       0.95      0.95      0.94      1145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generation kfolds to cross validation process\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "i = 0\n",
    "\n",
    "# start cross validation\n",
    "for train, test in kfold.split(X_train, Y_train):\n",
    "    model = baseline_model()\n",
    "    model.fit(X_train[train], Y_train[train], epochs=num_epochs, batch_size=batch_size, verbose=0,\n",
    "              callbacks=[TensorBoard(log_dir='./nn/tensorboard/'),\n",
    "                         ModelCheckpoint(path_best+'checkpoint-%d.h5' %(i), monitor='acc', verbose=0,\n",
    "                                         save_best_only=True, mode='max'),\n",
    "                         EarlyStopping(monitor='loss', min_delta=0.001, patience=10, verbose=2, mode='min')])\n",
    "    scores = model.evaluate(X_train[test], Y_train[test], verbose=2)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    i += 1\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load best model and test it \n",
      "Metrics =>  ['loss', 'acc'] [0.095308599793494528, 0.96855895196506547]\n",
      "\n",
      "Confusion Matrix :\n",
      "[[1077    0    1]\n",
      " [  18    7    1]\n",
      " [  34    0    7]]\n",
      "\n",
      "Metrics =>  ['loss', 'acc'] [0.095308599793494528, 0.96855895196506547]\n",
      "\n",
      "Classification Report : \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      1078\n",
      "          1       1.00      0.27      0.42        26\n",
      "          2       0.78      0.17      0.28        41\n",
      "\n",
      "avg / total       0.95      0.95      0.94      1145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate best model based on higher accuracy\n",
    "vect_max = np.argmax(cvscores)\n",
    "evaluete_nn(X_test, Y_test, vect_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
