{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Network\n",
    "\n",
    "Nel campo dell'**Intelligienza Artificiale** (_AI_) le **Neural Network** (_NN_) rappresentano\n",
    "uno degli approcci principali per permettere di compiere a sistemi automatici dei\n",
    "task molto complessi e articolati che algoritmi classici (sequenziali) non sarebbero in grado di portare a termine se non con un grado di complessità elevato.\n",
    "\n",
    "Le basi di questo nuovo approccio risalgono alla metà del XIX secolo quando per la prima volta furono proposti algoritmi per l'apprendimento automatico. Obiettivo di questo nuovo tipo di approccio era quello di creare _strutture_ in grado di modellare un determinato fenomeno e riproporne il comportamento sotto determinate condizioni.\n",
    "\n",
    "Unità base di questa nuova struttura è il _**neurone**_. Con questo termine identifichiamo un oggetto in grado di simulare il comportamento di un neurone classico e di interconnettersi con altri per creare una rete. La gestione di queste uscite e di queste interconnessioni è stabilita dall'algoritmo di training che ha guidato la rete nella fase di addestramento appunto.\n",
    "\n",
    "È curioso notare come la prospettiva iniziale di questo approccio era quella di creare macchine intelligienti, in grado di auto apprendere e riuscire ad eseguire in maniera intelligente i task che vengono sottomessi.\n",
    "\n",
    "Un tipico esempio di struttura base di queste reti è il **percettrone**\n",
    "![Percettrone](./img/percetrone.png)\n",
    "\n",
    "Ogni singolo ingresso rappresenta il contributo che viene fornito da una particolare caratteristica del fenomeno atto dell'analisi. Tutti questi contributi apportano, in maniera pesata, il proprio apporto verso la particolare funzione di trasferimento del sistema, la cui uscita, in combinazione con una determinata funzione di attivazione, viene riportata al di fuori del sistema e rappresenta il valore interpretato dal neurone in base agli ingressi forniti.\n",
    "\n",
    "Ponenedo in cascata e combinando tra loro più percettroni (o più genericamente più neuroni) generiamo quella che definiamo rete neurale\n",
    "![ANN](./img/ann.png)\n",
    "\n",
    "Nel corso degli anni l'interesse rivolto a questa nuova metodologia è andato via via scemando. Di pari passo però altri hanno proseguito lo studio delle reti neurali dandovi un taglio più matematico e sistemico grazie all'avvento di nuove metodologie come il **machine learinig**.\n",
    "\n",
    "\n",
    "Grazie a questo nuovo tipo di approccio, i modelli attuali di reti neurali risultano molto più complessi e performanti dei loro antenati. A partire dalla metà degli anni 80 del secolo scorso, il campo dell'intelligineza arificiale, avendo acquisito maggiore autorevolezza e rigore scientifico, è diventato uno dei più floridi terreni di ricerca. I risultati e i campi applicativi acquisiscono, di giorno in giorno, sempre maggiore interesse. Siamo così passati ad analizzare, attraverso le reti neurali, problemi sempre più complessi: è l'avvento del **deep learning**.\n",
    "\n",
    "Nelle reti neurali classiche moderne è possible riscontrare la presenza di qualche strato nascoto. Questi strati, denominati _hidden layers_, possono essere interpretati come il _cuore_ della rete stessa pocihé sono quelli che si occupano di interpretare le features sottomesse alla rete.\n",
    "\n",
    "![NN](./img/simple_neural_network_header.jpg)\n",
    "\n",
    "Con il deep learning, invece, siamo rapportati a problemi più complessi: _dal riconoscimento ed interpretazione del linguaggio naturale fino alla visione artificiale_. Nei modelli deep ogni singolo starto nascosto potrebbe essere paragonato ad una piccola rete neurale classica: ponenondone in cascata una all'altra possiamo ottnere modelli complessi per la gestione di task anche molto avanzati come ad esempio gli algoritmi di visione per l'_automotive_\n",
    "\n",
    "![deep](./img/deep.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Codice utlizzato per la Neural Network del caso di studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout\n",
    "# keras libraries\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# project libraries\n",
    "from src.nn.keras_nn import load_data_nn\n",
    "\n",
    "# convolutional network parmas\n",
    "path_dataset = './dataset/dataset_total.txt'  # datasetpath\n",
    "path_best = './best_model/'  # kfolds model path\n",
    "path_thebest = './thebetter_model/'  # bset models path\n",
    "\n",
    "# neural network params\n",
    "batch_size = 32  # training cases batch\n",
    "num_epochs = 500  # max number of epochs\n",
    "num_classes = 3  # number of class in dataset\n",
    "seed = 42  # base random seed\n",
    "n_splits = 10  # number of kfold\n",
    "n_input_layer = 31 # number of inputs layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_nn():\n",
    "    \"\"\"\n",
    "    generate dataset based on data in dataset folder\n",
    "    :return: train and test dataset based on stratification strategy\n",
    "    \"\"\"\n",
    "    dataset = np.loadtxt(path_dataset, delimiter='\\t')\n",
    "\n",
    "    y = np.array(np.ceil(dataset[:, -1])).astype(np.str)\n",
    "    X = np.array(dataset[:, :-1]).astype(np.float32)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=seed, stratify=y)\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "\n",
    "    X_train = scaler.transform(x_train)\n",
    "    X_test = scaler.transform(x_test)\n",
    "\n",
    "    y_train = np.subtract(y_train.reshape((len(y_train), 1)).astype(np.float32), np.asarray(2.0))\n",
    "    y_test = np.subtract(y_test.reshape((len(y_test), 1)).astype(np.float32), np.asarray(2.0))\n",
    "\n",
    "    Y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "    Y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    \"\"\"\n",
    "    Definition of neural network base model\n",
    "    :return: model\n",
    "    \"\"\"\n",
    "    base_model = Sequential()\n",
    "    base_model.add(Dense(n_input_layer, activation='elu',  input_shape=(X_train.shape[1],)))\n",
    "    #hidden\n",
    "    base_model.add(Dense(31, activation='elu'))\n",
    "    base_model.add(Dropout(0.1))\n",
    "    base_model.add(Dense(31, activation='elu'))\n",
    "    base_model.add(Dropout(0.1))\n",
    "    base_model.add(Dense(31, activation='elu'))\n",
    "    base_model.add(Dropout(0.1))\n",
    "    base_model.add(Dense(31, activation='elu'))\n",
    "    base_model.add(Dropout(0.3))\n",
    "    base_model.add(Dense(3, activation='softmax'))\n",
    "    base_model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluete_nn(X_test, Y_test, best_model):\n",
    "    \"\"\"\n",
    "    Evaluate best model after kfold training\n",
    "    :param X_test: example images to test best model after kfold\n",
    "    :param Y_test: labels matching truth to example\n",
    "    :param best_model: index which identify best model after kfold\n",
    "    :return: evaluation of best model trough dataset test and save it with loss and accuracy metrics\n",
    "    \"\"\"\n",
    "\n",
    "    # load best model and evaluate it with accuracy and loss\n",
    "    print('Load best model and test it ')\n",
    "    model = load_model(path_best+'checkpoint-%d.h5' %(best_model))\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)  # evaluate model\n",
    "    print('Metrics => ', model.metrics_names, score)\n",
    "    y_predict = np.asarray(model.predict(X_test, verbose=0))\n",
    "    Y_predict = np.argmax(y_predict, axis=1)\n",
    "    y_test = np.argmax(Y_test, axis=1)\n",
    "    confmatrix = confusion_matrix(y_test, Y_predict)\n",
    "    print(\"\\nConfusion Matrix :\")\n",
    "    print(confmatrix)\n",
    "    class_names = [\"0\", \"1\", '2']\n",
    "    print(\"\\nMetrics => \", model.metrics_names, score)\n",
    "    print('\\nClassification Report : ')\n",
    "    print(classification_report(y_test, Y_predict, target_names=class_names))\n",
    "    # save model tested with loss and accuracy\n",
    "    model.save(path_thebest+'model-'+'{:.4f}'.format(score[0])+'-'+'{:.4f}'.format(score[1])+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING FITTING NEURAL NETWORK\n",
      "loading data .......\n"
     ]
    }
   ],
   "source": [
    "print('STARTING FITTING NEURAL NETWORK')\n",
    "if os.path.exists(path_best):\n",
    "    shutil.rmtree(path_best)\n",
    "os.mkdir(path_best)\n",
    "if not os.path.exists(path_thebest):\n",
    "    os.mkdir(path_thebest)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = load_data_nn()\n",
    "\n",
    "print('loading data .......')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00052: early stopping\n",
      "acc: 96.13%\n",
      "Epoch 00041: early stopping\n",
      "acc: 97.50%\n",
      "Epoch 00056: early stopping\n",
      "acc: 95.76%\n",
      "Epoch 00037: early stopping\n",
      "acc: 96.88%\n",
      "Epoch 00037: early stopping\n",
      "acc: 96.50%\n",
      "Epoch 00054: early stopping\n",
      "acc: 96.25%\n",
      "Epoch 00031: early stopping\n",
      "acc: 94.51%\n",
      "Epoch 00046: early stopping\n",
      "acc: 96.88%\n",
      "Epoch 00041: early stopping\n",
      "acc: 96.38%\n",
      "Epoch 00056: early stopping\n",
      "acc: 97.25%\n",
      "96.40% (+/- 0.81%)\n",
      "Load best model and test it \n",
      "Metrics =>  ['loss', 'acc'] [0.095308599793494528, 0.96855895196506547]\n",
      "\n",
      "Confusion Matrix :\n",
      "[[1077    0    1]\n",
      " [  18    7    1]\n",
      " [  34    0    7]]\n",
      "\n",
      "Metrics =>  ['loss', 'acc'] [0.095308599793494528, 0.96855895196506547]\n",
      "\n",
      "Classification Report : \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      1078\n",
      "          1       1.00      0.27      0.42        26\n",
      "          2       0.78      0.17      0.28        41\n",
      "\n",
      "avg / total       0.95      0.95      0.94      1145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generation kfolds to cross validation process\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "i = 0\n",
    "\n",
    "# start cross validation\n",
    "for train, test in kfold.split(X_train, Y_train):\n",
    "    model = baseline_model()\n",
    "    model.fit(X_train[train], Y_train[train], epochs=num_epochs, batch_size=batch_size, verbose=0,\n",
    "              callbacks=[TensorBoard(log_dir='./nn/tensorboard/'),\n",
    "                         ModelCheckpoint(path_best+'checkpoint-%d.h5' %(i), monitor='acc', verbose=0,\n",
    "                                         save_best_only=True, mode='max'),\n",
    "                         EarlyStopping(monitor='loss', min_delta=0.001, patience=10, verbose=2, mode='min')])\n",
    "    scores = model.evaluate(X_train[test], Y_train[test], verbose=2)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    i += 1\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load best model and test it \n",
      "Metrics =>  ['loss', 'acc'] [0.095308599793494528, 0.96855895196506547]\n",
      "\n",
      "Confusion Matrix :\n",
      "[[1077    0    1]\n",
      " [  18    7    1]\n",
      " [  34    0    7]]\n",
      "\n",
      "Metrics =>  ['loss', 'acc'] [0.095308599793494528, 0.96855895196506547]\n",
      "\n",
      "Classification Report : \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      1078\n",
      "          1       1.00      0.27      0.42        26\n",
      "          2       0.78      0.17      0.28        41\n",
      "\n",
      "avg / total       0.95      0.95      0.94      1145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate best model based on higher accuracy\n",
    "vect_max = np.argmax(cvscores)\n",
    "evaluete_nn(X_test, Y_test, vect_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
