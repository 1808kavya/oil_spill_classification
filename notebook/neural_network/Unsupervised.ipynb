{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codice utlizzato per la Deep Neural Network applicato al  nostro caso di studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per tentare di ridefinire gli insiemi delle classi abbiamo utilizzato un approccio _unsupervised_. Abbiamo lasciato che le immagini fossero elaborate da un _autoencoder_ [2](#cite-SCHMIDHUBER201585) e ridistribuite secondo un associazione morfologica.\n",
    "\n",
    "L'utilizzo degli autoencoder è largamente usato nell'approccio non supervisionato. L'obiettivo di questo \"oggetto\" è dapprima tentare di ridurre la dimensionalità dei dati che cerca di esaminare e poi provare a ricostruire questi ultimi misurando alla fine quanto la ricostruzione si discosta dal dato reale.\n",
    "\n",
    "![autoencoder](https://upload.wikimedia.org/wikipedia/commons/2/28/Autoencoder_structure.png)\n",
    "\n",
    "Questo tipo di strutture sono spesso impiegate nei sistemi che devono fornire risposte in tempi relativamente brevi, come ad esempio il riconoscimento dei volti nelle immagini; inoltre, il modello creato potrebbe essere utilizzato per una valutazione parallela rispetto a quella dell'esperto per valutarne la bontà delle scelte.\n",
    "\n",
    "Nel nostro caso specifico abbiamo sfruttato pienamente la parte di encoder per ridurre la dimensionalità [1](#cite-hinton2006reducing) delle nostre immagini, in modo da risaltarne pienamente le caratteristiche morfologiche per ciascuna di esse. L'uscita di questo è stata posta in ingresso ad un _clusterizzatore_ classico che sfruttasse la tecnica del *k_means*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# standard libraries\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping as ES\n",
    "# keras libraries\n",
    "from keras.layers import Input, Dense, Dropout, Activation\n",
    "from keras.models import Model, Sequential\n",
    "import imageio\n",
    "# sklearn libraries\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import mixture\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to save files\n",
    "path_dataset = './crop_r_uns'  # dataset base path\n",
    "path_img_out = './img_cluster_uns'  # path to save clustered images\n",
    "path_model = './model_uns/'  # path to save autoencoder model\n",
    "path_board = './tensorboard/'\n",
    "\n",
    "# unsupervised neural network params\n",
    "batch_size = 32  # training cases batch\n",
    "num_epochs = 500  # max number of epochs\n",
    "out_encoder = 4  # number of neuron of encoder layer\n",
    "seed = 42   # base random seed\n",
    "\n",
    "# dataset image parameters\n",
    "height = 32\n",
    "width = 32\n",
    "depth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING FITTING UNSUPERVISED NEURAL NETWORK\n",
      "loading data .........\n"
     ]
    }
   ],
   "source": [
    "print('STARTING FITTING UNSUPERVISED NEURAL NETWORK')\n",
    "if not os.path.exists(path_model):\n",
    "    os.mkdir(path_model)\n",
    "if os.path.exists(path_board):\n",
    "    shutil.rmtree(path_board)\n",
    "    os.mkdir(path_board)\n",
    "X_train, Y_train, filenames= _load_data_uns()\n",
    "print('loading data .........')\n",
    "num_classes = np.unique(Y_train).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo definito una funzione che generasse un nuovo dataset di immagni a partire dalla clusterizzazione, inoltre, per testare e valutare il risultato, abbiamo fatto in modo che le immagini fossero salvate nel nuovo path con il riferimento alla vecchia classe di appartenenza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_clustering(X, kmeans, path, filenames, predict=False):\n",
    "\n",
    "    names = []\n",
    "    for i in range(len(filenames)):\n",
    "        names.append(filenames[i][20:-4])\n",
    "    if predict:\n",
    "        idx0 = np.where(kmeans == 0)\n",
    "        idx1 = np.where(kmeans == 1)\n",
    "        idx2 = np.where(kmeans == 2)\n",
    "    else:\n",
    "        idx0 = np.where(kmeans.labels_ == 0)\n",
    "        idx1 = np.where(kmeans.labels_ == 1)\n",
    "        idx2 = np.where(kmeans.labels_ == 2)\n",
    "\n",
    "    image0 = X[idx0]\n",
    "    image1 = X[idx1]\n",
    "    image2 = X[idx2]\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    i = 0\n",
    "    os.mkdir(path)\n",
    "    os.mkdir(path + \"/0/\")\n",
    "    for im in image0:\n",
    "        p = path + \"/0/\" + names[idx0[0][i]] + \".png\"\n",
    "        image = np.asarray(im).reshape(height, width)\n",
    "        imageio.imwrite(p, image)\n",
    "        i = i + 1\n",
    "    i = 0\n",
    "    os.mkdir(path + \"/1/\")\n",
    "    for im in image1:\n",
    "        p = path + \"/1/\" + names[idx1[0][i]] + \".png\"\n",
    "        image = np.asarray(im).reshape(height, width)\n",
    "        imageio.imwrite(p, image)\n",
    "        i = i + 1\n",
    "    i = 0\n",
    "    os.mkdir(path + \"/2/\")\n",
    "    for im in image2:\n",
    "        p = path + \"/2/\" + names[idx2[0][i]] + \".png\"\n",
    "        image = np.asarray(im).reshape(height, width)\n",
    "        imageio.imwrite(p, image)\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data_uns():\n",
    "    \"\"\"\n",
    "    load dataset from path\n",
    "    :return: train dataset and file names\n",
    "    \"\"\"\n",
    "    filenames, labels = generate_dataset(path_dataset)\n",
    "    X_train = np.asarray(load_image(filenames))\n",
    "    Y_train = labels\n",
    "\n",
    "    return X_train, Y_train, filenames\n",
    "\n",
    "def load_image(filenames):\n",
    "    \"\"\"\n",
    "    load images from and array of path\n",
    "    :param filenames: array of file names to load\n",
    "    :return: an array of images\n",
    "    \"\"\"\n",
    "    images = [*map(lambda x: np.asarray([read_image(x)]).reshape((32, 32, 1)), filenames)]\n",
    "    return images\n",
    "\n",
    "def read_image(filename):\n",
    "    \"\"\"\n",
    "    load image from disk\n",
    "    :param filename: path of images\n",
    "    :return: image match to file name path\n",
    "    \"\"\"\n",
    "    return mpimg.imread(filename)\n",
    "\n",
    "def iterate_path(path):\n",
    "    \"\"\"\n",
    "    iterate path and sub path to generate an two array of images and labels\n",
    "    :param path: base path to investigate\n",
    "    :return: two array of file names and labels\n",
    "    \"\"\"\n",
    "    filenames_array = []\n",
    "    labels_array = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            filenames_array.append(os.path.join(root, name))\n",
    "            labels_array.append(int(os.path.basename(os.path.normpath(root))))\n",
    "    # labels_array = _one_hot_label(labels_array)\n",
    "    return filenames_array, labels_array\n",
    "\n",
    "\n",
    "def generate_dataset(base_path):\n",
    "    \"\"\"\n",
    "    produce a dataset for neural network from path\n",
    "    :param base_path: base path of dataset images\n",
    "    :return: two array with file name and labels\n",
    "    \"\"\"\n",
    "    filenames_array, labels_array = iterate_path(base_path)\n",
    "    return filenames_array, labels_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 8)                 8200      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              9216      \n",
      "=================================================================\n",
      "Total params: 17,492\n",
      "Trainable params: 17,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(8, activation='sigmoid', input_shape=(height*width,)))\n",
    "autoencoder.add(Dense(out_encoder))\n",
    "out_e = Activation('sigmoid')  # output encoder\n",
    "autoencoder.add(out_e)\n",
    "autoencoder.add(Dense(8, activation='sigmoid'))\n",
    "autoencoder.add(Dropout(0.5, seed=seed))\n",
    "autoencoder.add(Dense(height*width, activation='sigmoid'))\n",
    "\n",
    "# model generation\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "encoder = Model(autoencoder.input, out_e.output)\n",
    "print(autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4744 samples, validate on 528 samples\n",
      "Epoch 1/500\n",
      " - 1s - loss: 0.6737 - val_loss: 0.6519\n",
      "Epoch 2/500\n",
      " - 1s - loss: 0.6273 - val_loss: 0.6014\n",
      "Epoch 3/500\n",
      " - 1s - loss: 0.5766 - val_loss: 0.5533\n",
      "Epoch 4/500\n",
      " - 1s - loss: 0.5369 - val_loss: 0.5189\n",
      "Epoch 5/500\n",
      " - 1s - loss: 0.5104 - val_loss: 0.4970\n",
      "Epoch 6/500\n",
      " - 1s - loss: 0.4932 - val_loss: 0.4830\n",
      "Epoch 7/500\n",
      " - 1s - loss: 0.4830 - val_loss: 0.4739\n",
      "Epoch 8/500\n",
      " - 1s - loss: 0.4767 - val_loss: 0.4676\n",
      "Epoch 9/500\n",
      " - 1s - loss: 0.4694 - val_loss: 0.4633\n",
      "Epoch 10/500\n",
      " - 1s - loss: 0.4669 - val_loss: 0.4601\n",
      "Epoch 11/500\n",
      " - 1s - loss: 0.4647 - val_loss: 0.4577\n",
      "Epoch 12/500\n",
      " - 1s - loss: 0.4626 - val_loss: 0.4560\n",
      "Epoch 13/500\n",
      " - 1s - loss: 0.4613 - val_loss: 0.4546\n",
      "Epoch 14/500\n",
      " - 1s - loss: 0.4600 - val_loss: 0.4535\n",
      "Epoch 15/500\n",
      " - 1s - loss: 0.4589 - val_loss: 0.4527\n",
      "Epoch 16/500\n",
      " - 1s - loss: 0.4576 - val_loss: 0.4520\n",
      "Epoch 17/500\n",
      " - 1s - loss: 0.4574 - val_loss: 0.4514\n",
      "Epoch 18/500\n",
      " - 1s - loss: 0.4569 - val_loss: 0.4509\n",
      "Epoch 19/500\n",
      " - 1s - loss: 0.4559 - val_loss: 0.4505\n",
      "Epoch 20/500\n",
      " - 1s - loss: 0.4562 - val_loss: 0.4502\n",
      "Epoch 21/500\n",
      " - 1s - loss: 0.4546 - val_loss: 0.4499\n",
      "Epoch 22/500\n",
      " - 1s - loss: 0.4561 - val_loss: 0.4496\n",
      "Epoch 23/500\n",
      " - 1s - loss: 0.4560 - val_loss: 0.4494\n",
      "Epoch 24/500\n",
      " - 1s - loss: 0.4550 - val_loss: 0.4492\n"
     ]
    }
   ],
   "source": [
    "# reshape input\n",
    "X_train_r = np.asarray(X_train).reshape(-1, height*width)\n",
    "# print(X_train.shape[0])\n",
    "# batch_size=1\n",
    "# start fitting process\n",
    "autoencoder.fit(X_train_r, X_train_r,\n",
    "                epochs=num_epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_split=0.1,\n",
    "                verbose=2,\n",
    "                callbacks=[TensorBoard(log_dir='./uns_deep/tensorboard', histogram_freq=1, write_images=True,\n",
    "                                       write_grads=True),\n",
    "                           ES(monitor='val_loss', min_delta=0.001, patience=3,\n",
    "                                         verbose=0, mode='auto')]\n",
    ")\n",
    "\n",
    "autoencoder.save(path_model+'autoencoder.h5')\n",
    "\n",
    "encoded_img = encoder.predict(X_train_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizziamo il *k_means* per clusterizzare l'uscita del nostro encoder imponendo come numero di cluster il valore a noi noto delle classi che vorremmo in uscita, valore pari a 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_all = KMeans(n_clusters=num_classes, init='k-means++', random_state=seed)\\\n",
    "        .fit_predict(np.asarray(encoded_img).reshape(-1, out_encoder))\n",
    "unique_all, counts_all = np.unique(kmeans_all, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il risultato del nostro clusterizzatore lo sfruttiamo per ricreare un nuovo dataset nel quale le immagini sono ricollocate nella classe di appartenenza.\n",
    "\n",
    "Al termine di questo task proviamo a stimare quanto la classificazione iniziale sia _distante_ rispetto a quella prodotta dal nostro sistema non supervisionato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/claudio/Documents/oil_spill/lib/python3.5/site-packages/imageio/core/util.py:78: UserWarning: Lossy conversion from float32 to uint8, range [0, 1]\n",
      "  dtype_str, out_type.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ordered Count :  [3197 1618  457]\n",
      "\n",
      "Confusion Matrix :\n",
      "[[2999 1552  290]\n",
      " [  51   21   25]\n",
      " [ 147   45  142]]\n",
      "\n",
      "Classification Report : \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.62      0.75      4841\n",
      "          1       0.01      0.22      0.02        97\n",
      "          2       0.31      0.43      0.36       334\n",
      "\n",
      "avg / total       0.88      0.60      0.71      5272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_class = np.sort(counts_all)[::-1]\n",
    "ordered_v = np.empty(shape=kmeans_all.shape)\n",
    "if (counts_all != order_class).all:\n",
    "    idx_0 = np.asscalar(np.asarray(np.where(counts_all == order_class[0])))\n",
    "    idx_1 = np.asscalar(np.asarray(np.where(counts_all == order_class[1])))\n",
    "    idx_2 = np.asscalar(np.asarray(np.where(counts_all == order_class[2])))\n",
    "    ordered_v[np.asarray(np.where(kmeans_all == idx_0))] = 0\n",
    "    ordered_v[np.asarray(np.where(kmeans_all == idx_1))] = 1\n",
    "    ordered_v[np.asarray(np.where(kmeans_all == idx_2))] = 2\n",
    "\n",
    "unique_ord, counts_ord = np.unique(ordered_v, return_counts=True)\n",
    "_save_clustering(X=X_train_r, kmeans=ordered_v, path=path_img_out, filenames=filenames,\n",
    "                 predict=True)\n",
    "\n",
    "print('\\nOrdered Count : ', counts_ord)\n",
    "\n",
    "confmatrix = confusion_matrix(Y_train, ordered_v)\n",
    "print(\"\\nConfusion Matrix :\")\n",
    "print(confmatrix)\n",
    "\n",
    "class_names = [\"0\", \"1\", '2']\n",
    "\n",
    "print('\\nClassification Report : ')\n",
    "print(classification_report(Y_train, ordered_v, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come ci aspettavamo, i risultati sono abbastanza vicini per gli elementi di classe 0 (low risk), mentre sono molto distanti per gli elementi di classe 1 (medium risk). Per questa classe si passa addirittura da alcune centinaia di elementi a ben 1618 elementi. Questo dato è la conferma a quanto accenato per la CNN, il dataset originale è fortemente condizionato dalle scelte dell'esperto che ha effettuato la validazione degli esempi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "<a name=\"cite-schmidhuber201585\"/><sup>[^](#ref-1) </sup>Jürgen Schmidhuber. 2015. _Deep learning in neural networks: An overview_. [URL](http://www.sciencedirect.com/science/article/pii/S0893608014002135)\n",
    "\n",
    "<a name=\"cite-hinton2006reducing\"/><sup>[^](#ref-2) </sup>Hinton, Geoffrey E and Salakhutdinov, Ruslan R. 2006. _Reducing the dimensionality of data with neural networks_.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
